
# A Survey of LLM-Based Methods for Synthetic Data Generation and the Rise of Agentic Workflows
As AI systems become increasingly data-hungry, the need for high-quality datasets has never been greater. However, real-world data collection faces major challenges: scarcity, privacy constraints, and high acquisition costs. Synthetic Data Generation (SDG) offers a compelling alternative—creating artificial data that mimics real-world patterns without the associated drawbacks.

> 📌 This repository complements the survey [*A Survey of LLM-Based Methods for Synthetic Data Generation and the Rise of Agentic Workflows*](https://link.springer.com/chapter/10.1007/978-3-031-93418-6_9) by Ahmad Alismail and Carsten Lanquillon. It is a continuously updated resource collecting references on LLM-based synthetic data generation—supporting ongoing learning and collaboration in the research community.  
> 💡 If you’d like to contribute or suggest additions, feel free to open a pull request or issue!


## Table of Contents

- [Surveys](#surveys)
- [SDG Methods](#sdg-methods)
  - [Traditional Architectures: Single LLM without External Tools](#traditional-architectures-single-llm-without-external-tools)
  - [Agentic Workflows](#agentic-workflows)
- [Further Reading](#further-reading)
- [Related Repositories](#related-repositories)

# Surveys

| Publication                                                                                                                                          | Date    | Overview                                                                                                                                 |
| ---------------------------------------------------------------------------------------------------------------------------------------------------- | ------- | ---------------------------------------------------------------------------------------------------------------------------------------- |
| [Synthetic Data Generation Using Large Language Models: Advances in Text and Code](https://arxiv.org/pdf/2503.14023)                                 | 03-2025 | Reviews recent progress in using LLMs to generate synthetic text and code, covering methods, evaluation, and challenges.                 |
| [Recent Advances in Large Langauge Model Benchmarks against Data Contamination: From Static to Dynamic Evaluation](https://arxiv.org/abs/2502.17521) | 02-2025 | Surveys the evolution of LLM benchmarks from static datasets to dynamic systems to better handle data contamination.                     |
| [A Survey on Data Synthesis and Augmentation for Large Language Models](https://arxiv.org/abs/2410.12896)                                            | 10-2024 | Provides a broad overview of techniques and strategies for creating and augmenting data specifically for training large language models. |
| [Data Augmentation Using LLMs: Data Perspectives, Learning Paradigms, and Challenges](https://aclanthology.org/2024.findings-acl.97/)                | 08-2024 | Explores how LLMs can be used to augment data, discussing various data types, learning methods, and associated difficulties.             |
| [On LLMs- Driven Synthetic Data Generation, Curation, and Evaluation: A Survey](https://arxiv.org/abs/2406.15126)                                    | 06-2024 | Offers a comprehensive survey of the entire pipeline for using LLMs to create synthetic data, from generation to evaluation.             |
| [Best Practices and Lessons Learned on Synthetic Data](https://arxiv.org/abs/2404.07503)                                                             | 04-2024 | Summarizes key strategies, best practices, and lessons learned from enterprise applications of synthetic data generation.                |
| [A Survey on Data Augmentation in the Large Model Era](https://arxiv.org/abs/2401.15422)                                                             | 01-2024 | Reviews the landscape of data augmentation techniques, focusing on methods that are particularly effective for large-scale models.       |
| [Comprehensive Exploration of Synthetic Data Generation: A Survey](https://arxiv.org/abs/2401.02524)                                                 | 01-2024 | Provides a thorough survey of synthetic data generation, covering its history, methods, applications, and future challenges.             |

# SDG Methods
## Traditional Architectures: Single LLM without External tools

| **Title**                                                                                                                                                                                                                 | **Publication Date** | **Overview **                                                                                                                                       |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- |
| [O1 Replication Journey – Part 2: Surpassing O1-preview through Simple Distillation Big Progress or Bitter Lesson?](https://arxiv.org/abs/2411.16489)                                                                     | 11-2024              | A base model can outperform O1-preview on mathematical reasoning through simple knowledge distillation from O1's API.                               |
| [CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation](https://arxiv.org/abs/2310.15638)                                                                          | 10-2024              | Uses a large language model's uncertainty to decide whether a human or the model should handle data annotation for greater efficiency.              |
| [Self-Judge: Selective Instruction Following with Alignment Self-Evaluation](https://arxiv.org/abs/2409.00935)                                                                                                            | 09-2024              | Introduces a framework for a large language model to self-evaluate and decide whether to respond to a given prompt.                                 |
| [Automated test generation to evaluate tool-augmented LLMs as conversational AI agents](https://arxiv.org/abs/2409.15934)                                                                                                 | 09-2024              | Presents a method for automatically generating tests to evaluate how well tool-augmented LLMs perform as conversational agents.                     |
| [Is Child-Directed Speech Effective Training Data for Language Models?](https://arxiv.org/abs/2408.03617)                                                                                                                 | 08-2024              | Investigates the effectiveness of training language models on child-directed speech for better language acquisition.                                |
| [Case2Code: Learning Inductive Reasoning with Synthetic Data](https://arxiv.org/abs/2407.12504)                                                                                                                           | 07-2024              | Teaches large language models inductive reasoning by training them on synthetic input-output examples and their corresponding code.                 |
| [Scaling Synthetic Data Creation with 1,000,000,000 Personas](https://arxiv.org/abs/2406.20094)                                                                                                                           | 06-2024              | Presents a method for generating vast amounts of diverse synthetic data by prompting a large language model with a billion different personas.      |
| [WizardCoder: Empowering Code Large Language Models with Evol-Instruct](https://arxiv.org/abs/2306.08568)                                                                                                                 | 06-2024              | Introduces Evol-Instruct, a method for generating complex instruction data to train more capable code-generating language models.                   |
| [Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing](https://arxiv.org/abs/2406.08464)                                                                                                  | 06-2024              | Proposes generating large-scale alignment data by feeding simple pre-query templates to an already aligned model.                                   |
| [Self-Translate-Train: Enhancing Cross-Lingual Transfer of Large Language Models via Inherent Capability](https://arxiv.org/abs/2407.00454)                                                                               | 06-2024              | Improves the cross-lingual abilities of large language models by using their own translation capabilities to generate training data.                |
| [ToolCoder: Teach Code Generation Models to use API search tools](https://arxiv.org/abs/2305.04032)                                                                                                                       | 05-2024              | Teaches code-generating models to use API search tools for finding relevant APIs for specific tasks.                                                |
| [DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data](https://arxiv.org/abs/2405.14333)                                                                                                 | 05-2024              | Proposes a framework and a large synthetic dataset to improve theorem-proving abilities of large language models in natural language.               |
| [Phi-3 Technical Report](https://arxiv.org/abs/2404.14219)                                                                                                                                                                | 04-2024              | Details the architecture, training, and capabilities of the Phi-3 family of small, powerful, open-source multimodal models.                         |
| [Can ChatGPT Reproduce Human-Generated Labels? A Study of Social Computing Tasks](https://arxiv.org/abs/2304.10145)                                                                                                       | 04-2024              | Investigates how well ChatGPT can replicate human-generated data labels for various social computing tasks.                                         |
| [OpenMathInstruct-1: A 1.8 Million Math Instruction Tuning Dataset](https://proceedings.neurips.cc/paper_files/paper/2024/hash/3d5aa9a7ce28cdc710fbd044fd3610f3-Abstract-Datasets_and_Benchmarks_Track.html)              | 02-2024              | Introduces a dataset of 1.8 million math problems and solutions to improve the mathematical reasoning of open-source language models.               |
| [Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling](https://arxiv.org/abs/2401.16380)                                                                                                         | 01-2024              | Presents a method for more efficient language model training by rephrasing web documents into different styles like Wikipedia articles.             |
| [Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models](https://arxiv.org/abs/2401.01335)                                                                                                         | 01-2024              | Shows that a language model can improve its reasoning and problem-solving skills by "playing" against itself to solve problems.                     |
| [Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models](https://arxiv.org/abs/2312.06585)                                                                                                     | 12-2023              | Explores a self-training method where a model generates and filters its own training data to improve problem-solving skills.                        |
| [Orca 2: Teaching Small Language Models How to Reason](https://arxiv.org/abs/2311.11045)                                                                                                                                  | 11-2023              | Presents a method to teach smaller language models different reasoning strategies for various tasks, enhancing their overall capabilities.          |
| [Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models](https://arxiv.org/abs/2311.00287)                                                                         | 11-2023              | Examines using large language models and techniques like retrieval-augmented generation to create structured medical text data.                     |
| [HELPSTEER: Multi-attribute Helpfulness Dataset for STEERLM](https://arxiv.org/abs/2311.09528)                                                                                                                            | 11-2023              | Introduces a dataset annotating model response helpfulness across multiple attributes (e.g., correctness, coherence) to improve training.           |
| [ULTRAFEEDBACK: Boosting Language Models with Scaled AI Feedback](https://arxiv.org/abs/2310.01377)                                                                                                                       | 10-2023              | Explores using large-scale AI-generated feedback to align language models with human preferences and presents a corresponding dataset.              |
| [Textbooks Are All You Need II: phi-1.5 technical report](https://arxiv.org/abs/2309.05463)                                                                                                                               | 09-2023              | Describes phi-1.5, a 1.3B parameter model trained on high-quality "textbook" data for common sense reasoning.                                       |
| [MAMMOTH: BUILDING MATH GENERALIST MODELS THROUGH HYBRID INSTRUCTION TUNING](https://arxiv.org/abs/2309.05653)                                                                                                            | 09-2023              | Introduces open-source language models trained on a diverse set of math problems to improve general math problem-solving skills.                    |
| [METAMATH: BOOTSTRAP YOUR OWN MATHEMATICAL QUESTIONS FOR LARGE LANGUAGE](https://arxiv.org/abs/2309.12284)                                                                                                                | 09-2023              | Improves mathematical reasoning in language models by rewriting existing math questions from various perspectives for a more diverse training set.  |
| [DISC-MedLLM: Bridging General Large Language Models and Real-World Medical Consultation](https://arxiv.org/abs/2308.14346)                                                                                               | 08-2023              | Presents a language model trained on high-quality medical data for more accurate and reliable healthcare-related conversations.                     |
| [Textbooks Are All You Need](https://arxiv.org/abs/2306.11644)                                                                                                                                                            | 07-2023              | Argues that training language models on high-quality, "textbook-style" data yields better performance than training on unfiltered web data.         |
| [AlpaGasus: Training A Better Alpaca with Fewer Data](https://arxiv.org/abs/2307.08701)                                                                                                                                   | 07-2023              | Shows that filtering low-quality examples from the Alpaca dataset allows for training a better model with significantly less data.                  |
| [BEAVERTAILS: Towards Improved Safety Alignment of LLM via a Human-Preference Dataset](https://proceedings.neurips.cc/paper_files/paper/2023/hash/4dbb61cb68671edc4ca3712d70083b9f-Abstract-Datasets_and_Benchmarks.html) | 07-2023              | Introduces a dataset that separately annotates helpfulness and harmlessness of model responses for better safety alignment.                         |
| [Orca: Progressive Learning from Complex Explanation Traces of GPT-4](https://arxiv.org/abs/2306.02707)                                                                                                                   | 06-2023              | Introduces Orca, a model that learns to imitate the reasoning process of larger models like GPT-4 by training on their detailed explanation traces. |
| [TinyStories: how Small Can Language Models Be and Still Speak Coherent English?](https://arxiv.org/abs/2305.07759)                                                                                                       | 05-2023              | Explores the minimum size for language models to generate coherent English by training them on synthetic children's stories.                        |
| [WizardLM: Empowering Large Language Models to Follow Complex Instructions](https://arxiv.org/abs/2304.12244)                                                                                                             | 04-2023              | Creates large amounts of instruction-following data with varying complexity to improve how language models follow complex instructions.             |
| [Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data](https://arxiv.org/abs/2304.01196)                                                                                                    | 04-2023              | Creates a multi-turn chat dataset by having ChatGPT converse with itself, then uses this data to train an open-source chat model.                   |
| [HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge](https://arxiv.org/abs/2304.06975)                                                                                                                             | 04-2023              | Details fine-tuning the LLaMA model with a large Chinese medical dataset to create a specialized medical language model.                            |
| [Instruction Tuning with GPT-4](https://arxiv.org/abs/2304.03277)                                                                                                                                                         | 04-2023              | Demonstrates using GPT-4 to generate a large dataset of instruction-following examples for fine-tuning other language models.                       |
| [Alpaca: A Strong, Replicable Instruction-Following Model](https://crfm.stanford.edu/2023/03/13/alpaca.html)                                                                                                              | 03-2023              | Presents a language model fine-tuned on 52,000 instruction-following demonstrations generated by a larger model.                                    |
| [CHATGPT OUTPERFORMS CROWD WORKERS FOR TEXT-ANNOTATION TASKS](https://www.pnas.org/doi/abs/10.1073/pnas.2305016120)                                                                                                       | 03-2023              | Shows that for several text annotation tasks, ChatGPT performs better and is more cost-effective than human crowd workers.                          |
| [AugGPT: Leveraging ChatGPT for Text Data Augmentation](https://ieeexplore.ieee.org/abstract/document/10858342/)                                                                                                          | 02-2023              | Proposes using ChatGPT to rephrase training sentences to create a more diverse and larger dataset for model training.                               |
| [SELF-INSTRUCT: Aligning Language Models with Self-Generated Instructions](https://arxiv.org/abs/2212.10560)                                                                                                              | 12-2022              | Introduces a method for a language model to generate its own instruction-following data for self-improvement through fine-tuning.                   |
| [CORE: A Retrieve-then-Edit Framework for Counterfactual Data Generation](https://arxiv.org/abs/2210.04873)                                                                                                               | 12-2022              | Presents a "retrieve-then-edit" framework where a model finds and modifies text to create counterfactual examples.                                  |
| [DISCO: Distilling Counterfactuals with Large Language Models](https://arxiv.org/abs/2212.10534)                                                                                                                          | 12-2022              | Proposes generating high-quality, large-scale counterfactual data by using a syntactic parser to guide a large language model.                      |
| [STaR: Self-Taught Reasoner: Bootstrapping Reasoning With Reasoning](https://research.google/pubs/star-self-taught-reasoner-bootstrapping-reasoning-with-reasoning/)                                                      | 03-2022              | Introduces a method for a language model to learn reasoning by generating its own rationales for problems and then fine-tuning on the correct ones. |

## Agentic Workflows


| Publication                                                                                                                                     | Date    | Overview                                                                                                                                                                                                                                                                                                           |
| ----------------------------------------------------------------------------------------------------------------------------------------------- | ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| [Benchmarking Agentic Workflow Generation](https://arxiv.org/abs/2410.07869)                                                                    | 10-2024 | Introduces [**WORFBENCH**](https://github.com/zjunlp/WorfBench), a comprehensive benchmark designed to evaluate how well large language model (LLM) agents can generate workflows—that is, structured plans of subtasks needed to solve complex problems.                                                          |
| [BenchAgents: Automated Benchmark Creation With Agent Interaction](https://arxiv.org/abs/2410.22584)                                            | 10-2024 | Introduces a framework where AI agents interact with each other to automatically create new and challenging benchmarks.                                                                                                                                                                                            |
| [The Fellowship of the LLMs: Multi-Agent Workflows for Synthetic Preference Optimization Dataset Generation](https://arxiv.org/abs/2408.08688)  | 08-2024 | Uses a team of AI agents, each with a specific role, to generate high-quality datasets for training and aligning language models.                                                                                                                                                                                  |
| [AgentInstruct: Toward Generative Teaching with Agentic Flows](https://arxiv.org/abs/2407.03502)                                                | 07-2024 | Introduces a framework to generate synthetic data for instruction-tuning. Instead of relying on human-curated prompts or limited seed sets, they use a network of AI agents, combined with tools and reflection loops—to turn raw content (e.g., documents, code) into 25 million prompt–response pairs. |
| [Arena Learning: Build Data Flywheel for LLMs Post-Training via Simulated Chatbot Arena](https://arxiv.org/abs/2407.10627)                      | 07-2024 | Proposes a simulated "arena" where chatbots compete, generating preference data that is used to continuously improve the models.                                                                                                                                                                                   |
| [MALLM-GAN: Multi-Agent Large Language Model as Generative Adversarial Network for Synthesizing Tabular Data](https://arxiv.org/abs/2406.10521) | 06-2024 | Leverages a multi-agent system within a GAN framework to improve the generation of realistic synthetic tabular data.                                                                                                                                                                                               |
| [Advancing LLM Reasoning Generalists With Preference Trees](https://arxiv.org/abs/2404.02078)                                                   | 04-2024 | Improves a model's reasoning skills by having it explore and evaluate multiple reasoning paths, forming a "preference tree" of the best steps.                                                                                                                                                                     |
| [LAB: Large-Scale Alignment for Chatbots](https://arxiv.org/abs/2403.01081)                                                                     | 03-2024 | Introduces a large-scale dataset of human-AI conversations and a new method to more effectively align chatbots with human preferences.                                                                                                                                                                             |
| [Benchmark self-evolving: A multi-agent framework for dynamic LLM evaluation](https://arxiv.org/abs/2402.11443)                                 | 02-2024 | Proposes a framework where multiple AI agents work together to continuously update and evolve evaluation benchmarks for LLMs.                                                                                                                                                                                      |
| [Synthetic data (almost) from scratch: Generalized instruction tuning for language models](https://arxiv.org/abs/2402.13064)                    | 02-2024 | Uses a small set of human-written examples to bootstrap the generation of a large, diverse synthetic dataset for instruction tuning.                                                                                                                                                                               |
| [Orca-math: Unlocking the potential of SLMs in grade school math](https://arxiv.org/abs/2402.14830)                                             | 02-2024 | Creates a high-quality synthetic dataset of math problems to significantly improve the mathematical reasoning of smaller language models (SLMs).                                                                                                                                                                   |
| [Learning From Mistakes Makes LLM a Better Reasoner](https://arxiv.org/abs/2310.20689)                                                          | 10-2023 | Improves a model's reasoning abilities by training it on data that includes common mistakes and provides corrective feedback.                                                                                                                                                                                      |

# Further Reading


| Publication                                                                                                             | Date    | Notes                                                                                                                                                                                                                                                              |
| ----------------------------------------------------------------------------------------------------------------------- | ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| [Evaluating Language Models as Synthetic Data Generators](https://arxiv.org/abs/2412.03679)                             | 12-2024 | a benchmark that evaluates LLMs’ abilities to generate synthetic data by comparing outputs from multiple models and analyzing quality metrics (e.g., perplexity, difficulty), revealing that data-generation prowess doesn’t always match problem-solving strength |
| [On the Diversity of Synthetic Data and its Impact on Training Large Language Models](https://arxiv.org/abs/2410.15226) | 10-2024 | Introduces a diversity metric (“LLM cluster-agent”) to quantify synthetic data variety, demonstrating that data diversity boosts model performance—especially during fine-tuning—even for smaller-scale LLMs                                                       |
| [Scaling Laws of Synthetic Data for Language Models](https://arxiv.org/abs/2503.19551)                                  | 03-2025 | Presents _SynthLLM_, a framework revealing that synthetic pre-training data follows power-law scaling up to 300B tokens, and larger LLMs require fewer synthetic tokens to reach optimal performance                                                               |

# Related Repositories

| [Awesome Synthetic Datasets](https://github.com/davanstrien/awesome-synthetic-datasets) | Practical resources for building synthetic text and vision datasets. |
| --------------------------------------------------------------------------------------- | -------------------------------------------------------------------- |
| [LLM Synthetic Data](https://github.com/wasiahmad/Awesome-LLM-Synthetic-Data/tree/main) | Papers, tools, and blogs on LLM-generated data.                      |
| [LLM-Datasets](https://github.com/mlabonne/llm-datasets/tree/main):                     | Curated datasets and tools for LLM post-training.                    |

